Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,2.196333,-0.5171929,130.0,-4.3523988654216135,-0.8704800323893627,1.0
20000,2.1886525,-0.4418026,130.0,-4.7148989796638485,-0.9429800279438496,1.0
30000,2.1766362,-0.38904324,130.0,-4.502399094216526,-0.9004800265887752,1.0
40000,2.1704495,-0.3169518,130.0,-4.314898956567049,-0.8629800355061888,1.0
50000,2.163842,-0.27277422,130.0,-4.864899160712957,-0.9729800114408136,1.0
60000,2.16097,-0.26896822,130.0,-4.2857324550549185,-0.8571466958771149,1.0
70000,2.154285,-0.23339394,130.0,-4.43989892527461,-0.8879800325259566,1.0
80000,2.1458747,-0.24165805,130.0,-4.002399113029242,-0.8004800269380212,1.0
90000,2.1343684,-0.2559619,130.0,-4.152398906648159,-0.8304800476878882,1.0
100000,2.1168096,-0.25877008,130.0,-3.389899004995823,-0.6779800444841385,1.0
110000,2.110418,-0.26580876,130.0,-3.522096033574957,-0.7044194269304475,1.0
